{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Keras - General Structure for a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "1. https://towardsdatascience.com/simple-introduction-to-convolutional-neural-networks-cdf8d3077bac\n",
    "2. https://www.pyimagesearch.com/2018/12/31/keras-conv2d-and-convolutional-layers/    \n",
    "3. https://stats.stackexchange.com/questions/291820/what-is-the-definition-of-a-feature-map-aka-activation-map-in-a-convolutio\n",
    "4. https://qph.fs.quoracdn.net/main-qimg-704ab7dc6b6ea6e7e919daab06a63537"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be seen as a general architecture for using Keras with Neural Networks for classifying images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, it is important to outline why we shall be looking at a convolutional neural network for image processing rather than say a standard multilayer perceptron model. There are three distinct problems with MLP's vs. CNN's for image processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- MLP's are not translation invariant. \n",
    "If a cat is in the top right hand corner of the image but then in the bottom left hand corner the MLP when then start 'modify' so that it now predicts cats as being in the bottom left hand corner. As such the model is not a robust approach for classifying images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- MLP's use one perceptron for each input.\n",
    "This leads to too many weights and overfitting can occur.\n",
    "If we were to look at a 224x224 image x3 (rgb=red,blue,green for each pixel), that would have to be flattened into a column matrix of 150,528. Not doubt, that means a lot of weights need to be trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- CNN's leverage the fact that nearby pixels are more strongly relate than distant ones. As such it 'understands', for lack of a better phrase, that objects are built up of smaller ones, allowing it to generalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "import numpy as np\n",
    "from tensorflow import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The seed is used to memorise the same random number\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways to construct Keras models: sequential and functional.\n",
    "\n",
    "The sequential API allows you to create models layer-by-layer for most problems. It is limited in that it does not allow you to create models that share layers or have multiple inputs or outputs.\n",
    "\n",
    "Alternatively, the functional API allows you to create models that have a lot more flexibility as you can easily define models where layers connect to more than just the previous and next layers. In fact, you can connect layers to (literally) any other layer. As a result, creating complex networks such as siamese networks and residual networks become possible.\n",
    "\n",
    "For the purposes of this example I shall be using a sequential neural network as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the classifier and adding layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier =Sequential()\n",
    "# Here we use 32 filters with a kernal size of 3x3\n",
    "# The input shape is 64x64 because that is the shape of the image and x3 because every pixel is in rbg (red,blue,green)\n",
    "classifier.add(Conv2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
    "\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "classifier.add(Conv2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "classifier.add(MaxPooling2D(2,2))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(128,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We continue adding dense layers as long as it improves the accuracy of our model\n",
    "classifier.add(Dense(128,activation='relu'))\n",
    "classifier.add(Dense(128,activation='relu'))\n",
    "classifier.add(Dense(128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filters Explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point it seems imperative to explain filters and how they give CNN's an advantage over MLP's. Here are some filter facts that can aid in understanding their purpose and how they function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- Filters allow us to analyse the effects of nearby pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2- A standard filter size is 3x3 or 5x5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3- Let's say we're looking for a nose. The filter shall move from top left to bottom right searching for the components of a nose. This way it doesn't matter if the nose is in the top left or bottom right or anywhere else for that matter. For each point on the image, a value is calculated based on the filter using a convolution operation. Our filter would tell us how strongly a nose appears, in what locations and how many times they appear. This reduces the number of weights that CNN uses vs. an MLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4- Each filter produces a feature map (also known as an activation map). Should it result in a high activation that means that a certain feature was found. The feature map is taken through an activation function. This decides once and for all if a certain feature was found at a certain location. The resulting output can then be referred to as a rectified feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5- We can also use pooling layers in order to select the largest values on the feature maps and use these as inputs to subsequent layers. In theory, any type of operation can be done in pooling layers, but in practice, only max pooling is used because we want to find the outliers â€” these are when our network sees the feature!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile The network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam', loss='binary_crossentropy',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = train_datagen.flow_from_directory('pneu/chest_xray/train',\n",
    "                                        target_size = (64, 64),\n",
    "                                        batch_size = 32,\n",
    "                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = test_datagen.flow_from_directory('pneu/chest_xray/val',\n",
    "                                        target_size = (64, 64),\n",
    "                                        batch_size = 32,\n",
    "                                        class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                        steps_per_epoch = 10000,\n",
    "                        epochs = 2,\n",
    "                        validation_data = test_set,\n",
    "                        validation_steps = 2500,\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying a New Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "new_image = image.load_img('/test_image.jpg', target_size = (64,64))\n",
    "new_image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the image by converting it into a numpy array using the img_to_array function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image.img_to_array(new_image)\n",
    "\n",
    "new_image = np.expand_dims(new_image, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = classifier.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if result[0][0] == 1:\n",
    "    prediction = 'Dog'\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
